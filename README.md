# ğŸ”´ NetPulse â€” Real-Time Network Anomaly Detection Dashboard

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.2.2-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![React](https://img.shields.io/badge/React-18-61DAFB?style=for-the-badge&logo=react&logoColor=black)
![WebSocket](https://img.shields.io/badge/WebSocket-Live-FF6B35?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

**Unsupervised deep learning system that detects network anomalies in real-time using LSTM Autoencoder reconstruction error.**

[Features](#-features) â€¢ [Architecture](#-ml-architecture) â€¢ [Quick Start](#-quick-start) â€¢ [Results](#-training-results) â€¢ [API](#-api-endpoints)

</div>

---

## ğŸ“Œ Overview

NetPulse monitors **6 network metrics simultaneously** and detects anomalies the moment they occur â€” no labeled data required.

Traditional monitoring uses static rules *(if CPU > 90% â†’ alert)*. This misses complex multi-feature anomalies where no single metric breaches a threshold but the **combination** of values is abnormal.

NetPulse solves this by training an **LSTM Autoencoder** exclusively on normal traffic. When anomalous data arrives, the model fails to reconstruct it accurately â€” producing a high reconstruction error that triggers an alert.

```
Live Data â†’ LSTM Encoder â†’ Latent Vector â†’ LSTM Decoder â†’ Reconstruction Error â†’ Anomaly Decision
```

> If reconstruction error > threshold (Î¼ + 2.5Ïƒ) â†’ ğŸš¨ Anomaly Detected

---

## âœ¨ Features

| Feature | Details |
|---|---|
| ğŸ”´ **Real-Time Streaming** | WebSocket at 500ms intervals â€” zero page refresh |
| ğŸ§  **Unsupervised ML** | LSTM Autoencoder â€” no labels needed |
| ğŸ“Š **6 Metrics** | CPU, Memory, Latency, Packet Loss, Bandwidth, Error Rate |
| ğŸš¨ **6 Anomaly Types** | CPU Spike, Memory Leak, Latency Surge, Packet Storm, Bandwidth Drop, Error Flood |
| ğŸ—ºï¸ **Network Topology** | Live SVG map with 6 animated nodes |
| ğŸ“ **CSV Export** | Download full anomaly log for post-incident analysis |
| âš¡ **Single Page** | No scrolling â€” entire dashboard visible at once |

---

## ğŸ§  ML Architecture

### LSTM Autoencoder (Seq2Seq)

```
Input Sequence (batch, 30, 6)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LSTM Encoder   â”‚  128 hidden units Â· 1 layer
â”‚  (reads input)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚  hidden state (1, batch, 128)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LSTM Decoder   â”‚  128 hidden units Â· autoregressive
â”‚  (reconstructs) â”‚  feeds own output as next input
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Dropout(0.3)
         â”‚
         â–¼
   Linear(128 â†’ 6)
         â”‚
         â–¼
Reconstructed Sequence (batch, 30, 6)
         â”‚
         â–¼
   MSE Loss = Reconstruction Error
```

### Anomaly Detection

```python
threshold = mean(val_errors) + 2.5 * std(val_errors)  # = 0.1852

if reconstruction_error > threshold:
    flag_anomaly()
```

### Why StandardScaler?

| Scaler | Variance | Baseline MSE | Model Learns? |
|---|---|---|---|
| MinMaxScaler | 0.027 | 0.022 (mean prediction) | âŒ No |
| **StandardScaler** | **1.000** | **1.000** | **âœ… Yes** |

> MinMaxScaler caused the model to simply predict the mean â€” achieving near-zero loss without learning anything.

---

## ğŸ“ Project Structure

```
netpulse/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ data_generator.py     # AR(1) synthetic telemetry + live streaming
â”‚   â”œâ”€â”€ model.py              # LSTM Autoencoder + AnomalyDetector
â”‚   â”œâ”€â”€ train.py              # Training pipeline
â”‚   â”œâ”€â”€ main.py               # FastAPI server + WebSocket
â”‚   â””â”€â”€ requirements.txt      # Python dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useWebSocket.js       # Real-time state management
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ Dashboard.jsx         # Single-page layout
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ Header.jsx            # Live stats bar
â”‚   â”‚       â”œâ”€â”€ MetricCard.jsx        # 6 metric cards
â”‚   â”‚       â”œâ”€â”€ TelemetryChart.jsx    # 3 real-time area charts
â”‚   â”‚       â”œâ”€â”€ NodeMap.jsx           # SVG network topology
â”‚   â”‚       â”œâ”€â”€ AnomalyTable.jsx      # Anomaly log + CSV export
â”‚   â”‚       â”œâ”€â”€ AlertBanner.jsx       # Toast notifications
â”‚   â”‚       â””â”€â”€ ModelInfo.jsx         # Model architecture panel
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ models/                   # Saved model weights (gitignored)
â”œâ”€â”€ data/                     # Training data (gitignored)
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### Prerequisites

```bash
Python 3.10+
Node.js 18+
```

### 1. Clone the repository

```bash
git clone https://github.com/umarfaraz511/Real-time-network-anomaly-detection-dashboard.git
cd Real-time-network-anomaly-detection-dashboard
```

### 2. Install backend dependencies

```bash
cd backend
pip install -r requirements.txt
```

### 3. Train the model

```bash
python train.py
```

Expected output:
```
Avg autocorrelation : 0.9342  (>0.85 = good temporal structure)
Scaled mean         : 0.0000  std: 1.0000

Epoch [  1/80] | Train: 0.84606 | Val: 0.79234 | Gap: 0.0472 âœ“
Epoch [ 10/80] | Train: 0.43746 | Val: 0.41123 | Gap: 0.0262 âœ“
Epoch [ 40/80] | Train: 0.17990 | Val: 0.18445 | Gap: 0.0045 âœ“
Epoch [ 80/80] | Train: 0.12839 | Val: 0.13102 | Gap: 0.0026 âœ“

Threshold : 0.185185
```

### 4. Start the backend

```bash
python main.py
# FastAPI running on http://localhost:8000
```

### 5. Install and start the frontend

```bash
cd ../frontend
npm install
npm run dev
# React running on http://localhost:5173
```

### 6. Open the dashboard

```
http://localhost:5173
```

---

## ğŸ“Š Training Results

| Metric | Value |
|---|---|
| Best Validation Loss | 0.1234 |
| Error Mean (Î¼) | 0.1233 |
| Error Std (Ïƒ) | 0.0247 |
| **Threshold (Î¼ + 2.5Ïƒ)** | **0.1852** |
| Train / Val Gap | < 0.05 âœ… |
| Anomaly Separation | ~5.6Ã— threshold |
| Avg Autocorrelation | 0.9342 |
| Total Parameters | 140,038 |

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| `WS` | `/ws/telemetry` | Live telemetry WebSocket stream |
| `GET` | `/api/status` | Server health and model status |
| `GET` | `/api/anomalies` | Last 50 detected anomalies |
| `GET` | `/api/anomalies/export` | Download anomaly log as CSV |
| `GET` | `/api/model/info` | Model architecture and threshold |
| `GET` | `/docs` | Swagger interactive API docs |

---

## ğŸ” Anomaly Types

| Type | Feature | Normal | Anomaly |
|---|---|---|---|
| CPU Spike | `cpu_usage` | 45 Â± 10 % | 85 Â± 8 % |
| Memory Leak | `memory_usage` | 60 Â± 8 % | 88 Â± 5 % |
| Latency Surge | `latency_ms` | 20 Â± 5 ms | 180 Â± 40 ms |
| Packet Storm | `packet_loss_pct` | 0.4 Â± 0.3 % | 18 Â± 6 % |
| Bandwidth Drop | `bandwidth_mbps` | 500 Â± 80 Mbps | 40 Â± 20 Mbps |
| Error Flood | `error_rate` | 0.018 Â± 0.01 | 0.45 Â± 0.10 |

---

## âš™ï¸ Tech Stack

**Backend**
- Python 3.10+
- PyTorch 2.2.2 â€” LSTM Autoencoder
- FastAPI + Uvicorn â€” REST API and WebSocket server
- scikit-learn â€” StandardScaler
- NumPy + Pandas â€” Data generation

**Frontend**
- React 18 + Vite
- Recharts â€” Real-time animated area charts
- TailwindCSS v4 â€” Cyberpunk dark UI
- Lucide React â€” Icons

---

## ğŸ§© Key Engineering Challenges Solved

<details>
<summary><b>Bug #1 â€” Entangled Encoder/Decoder Tensors</b></summary>

**Problem:** The decoder reused `self.fc` for both LSTM hidden state and decoder input â€” feeding identical tensors making learning impossible. Loss stuck at 0.022 from epoch 1.

**Fix:** Redesigned as proper autoregressive seq2seq. Encoder hidden/cell state initializes decoder. Decoder feeds its own output as the next timestep input.
</details>

<details>
<summary><b>Bug #2 â€” MinMaxScaler Mean-Learning Trap</b></summary>

**Problem:** MinMaxScaler produced variance of 0.027. Predicting the constant mean achieved MSE = 0.022. Model never learned despite 100 epochs.

**Fix:** Replaced with StandardScaler (zero mean, unit variance). Anomalies now score 152Ã— higher than normal data.
</details>

<details>
<summary><b>Bug #3 â€” Distribution Shift from Sequential Split</b></summary>

**Problem:** AR(1) data drifts over time. Sequential split gave validation a different distribution â€” causing overfitting (train 0.15, val 0.44, gap 0.29).

**Fix:** Shuffled all sliding-window sequences before splitting. Gap reduced from 0.29 to < 0.05.
</details>

<details>
<summary><b>Bug #4 â€” White Noise Data (Autocorrelation â‰ˆ 0)</b></summary>

**Problem:** Original generator used `np.random.normal()` â€” pure white noise. LSTMs learn temporal dependencies and cannot learn from i.i.d. noise.

**Fix:** Replaced with AR(1) autoregressive process. Autocorrelation: 0.85â€“0.99 across all features.
</details>

---

## ğŸ“ Thesis Connection

This project extends research from a **Master's thesis on Generative AI for Predictive Maintenance**. The core principle â€” training an autoencoder on normal data and using reconstruction error as the anomaly signal â€” is the same approach applied with GANs and VAEs in industrial IoT systems.

NetPulse demonstrates this principle in a network monitoring context with a complete production-ready real-time pipeline.

---

## ğŸ‘¤ Author

**Umar Faraz**
ML Engineer


---
<img width="956" height="447" alt="net 1" src="https://github.com/user-attachments/assets/b0a5c1ff-e236-49e6-acbb-835fa151c5ff" />

## ğŸ“„ License

This project is licensed under the MIT License.

---

<div align="center">
Built with PyTorch Â· FastAPI Â· React Â· WebSocket
<br/>
â­ Star this repo if you found it useful!
</div>
